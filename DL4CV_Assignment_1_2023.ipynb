{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6ayCViEg4nh"
      },
      "source": [
        "#### **Welcome to Assignment 4 on Deep Learning for Computer Vision.**\n",
        "This assignment is based on the content you learned in Week-4.\n",
        "\n",
        "#### **Instructions**\n",
        "1. Use Python 3.x to run this notebook\n",
        "2. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'. You should not change anything else in the code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
        "3. Read documentation of each function carefully.\n",
        "4. All the Best!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be working with Pytorch operations"
      ],
      "metadata": {
        "id": "vNCYqRmwY6-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will perform basic elementwise operations between two matrices\n",
        "\n",
        "Step1: Rearrange the give input x into a tensor of shape (10,5,5) and store it in x_resize \\\\\n",
        "Step2: Generate a gaussian random tensor (mean =0, variance=1) of shape (5,5) and store it in variable y1 \\\\\n",
        "Step3:  Generate a uniform random tensor (interval [0,1]) of shape (5,5) and store it in variable y2 \\\\\n",
        "Step4: Perform elementwise multiplication between x_resize and y1,such that the output will be of shape (10,5,5) and store it in variable mul_output1 \\\\\n",
        "Step5: Sum over the last two dimensions of mul_output1 and store it in final_output1. The shape of final_output1 should be ([10]) \\\\\n",
        "Step6: Repeat Step4 and Step5 for x_resize and y2"
      ],
      "metadata": {
        "id": "L9QdBGYHufCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#DO NOT CHANGE THE SEED\n",
        "torch.manual_seed(2)\n",
        "\n",
        "x = torch.randint(low=0,high=256,size=(1,250))\n",
        "##Your code here##\n",
        "\n",
        "x_resize = ___\n",
        "\n",
        "y1 = ___\n",
        "\n",
        "y2 = ___\n",
        "\n",
        "mul_output1 = ___\n",
        "\n",
        "final_output1 = ___\n",
        "\n",
        "mul_output2 = ___\n",
        "\n",
        "final_output2 = __\n",
        "\n",
        "## Your code ends here##\n",
        "\n",
        "print(torch.mean(final_output1+final_output2))"
      ],
      "metadata": {
        "id": "m86HK22lbX82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. What is mean of the sum of final_output1 and final_output2? (Choose the closest value)\n",
        "a) 1000 \\\\\n",
        "b) 2000 \\\\\n",
        "c) 3000 \\\\\n",
        "d) 4000"
      ],
      "metadata": {
        "id": "0cBZCI971zta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "qrrG4dJVrJLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will calculate L2 loss between predicted values and labels \\\\\n",
        "\n",
        "\n",
        "Step1: Resize the final_output1 and final_output2 from the above code to shape (10,1) and store it in o1 and o2 respectively \\\\\n",
        "Step2: Concatenate these two vectors o1 and o2 such that the shape of the resultant tensor is (10,2) and store it in final_output \\\\\n",
        "Step3: Pass the tensor final_output as input to ReLU function and store it in logits variable \\\\\n",
        "Step4: Calculate Eucledian norm of the difference (labels-logits)  across dimension = 1 and store it in eucledian_dist. Your output shape should be ([10])\n"
      ],
      "metadata": {
        "id": "ltP_kpSaw5lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##DO NOT CHANGE SEED##\n",
        "torch.manual_seed(0)\n",
        "\n",
        "labels = torch.randint(low=0,high=2000,size=(10,2)).type(torch.float)\n",
        "\n",
        "## Your code starts here##\n",
        "o1 = ___\n",
        "o2 = ___\n",
        "final_output = ___\n",
        "\n",
        "logits = ___\n",
        "\n",
        "eucledian_dist = ___\n",
        "\n",
        "## Your code ends here\n",
        "print(eucledian_dist.shape)\n",
        "loss = torch.sum(eucledian_dist)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "ODOjjSxzcC0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. What is sum of the elements of the eucledian norm? (Choose the closest value)\n",
        "a) 12000 \\\\\n",
        "b) 13000 \\\\\n",
        "c) 10000000 \\\\\n",
        "d) 20000000"
      ],
      "metadata": {
        "id": "Is38Rlaw1rfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "qh5kHWdArFgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will calculate gradient of a vector w.r.t to a function \\\\\n",
        "\n",
        "\n",
        "Step1: Generate gaussian random tensor (mean =0, variance=1) of shape(3) and store it in w \\\\\n",
        "Step2: Generate a uniform random tensor (interval [0,1]) of shape(3,3) and store it in X \\\\\n",
        "Step3: Calculate the matrix vector product between X and w and store it in pred \\\\\n",
        "Step4: Calculate L1 norm of the difference (labels - pred) and store it in temp. The output should be of shape [3] \\\\\n",
        "Step5: Calculate sum of all elements of temp and store it in variable loss \\\\\n",
        "Step6: Calculate the gradient of 'w' w.r.t function loss"
      ],
      "metadata": {
        "id": "4iNSrU1JyQnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.utils import tempdir\n",
        "##DO NOT CHANGE SEED\n",
        "torch.manual_seed(0)\n",
        "labels = torch.randint(low=-800,high=50,size=(3,1)).type(torch.float)\n",
        "\n",
        "## Your code starts here ##\n",
        "w = ___\n",
        "## Your code ends here ##\n",
        "\n",
        "w = w.requires_grad_()\n",
        "\n",
        "## Your code starts here ##\n",
        "X = ___\n",
        "\n",
        "pred = ___\n",
        "\n",
        "temp = ___\n",
        "\n",
        "loss = ___\n",
        "## Your code ends here ##\n",
        "\n",
        "loss.backward(retain_graph=True)\n",
        "\n",
        "## Your code starts here ##\n",
        "grad = torch.autograd.grad(___,___)\n",
        "## Your code ends here ##\n",
        "print(grad)"
      ],
      "metadata": {
        "id": "SzElfXHXnlBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. What is gradient of 'w' w.r.t loss function?\n",
        "a)  [-4.4869, -2.1056, -3.4464] \\\\\n",
        "b)  [4.4869, 2.1056, 3.4464] \\\\\n",
        "c)  [-5.3670, -6.2075, -2.4481] \\\\\n",
        "d)  [5.3670, 6.2075, 2.4481]"
      ],
      "metadata": {
        "id": "nv8xTOuA1j8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HDZI5BrJuDx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will be training a 1-hidden layer multi-layer perceptron on a randomly generated dataset."
      ],
      "metadata": {
        "id": "Tcj0r1IlxHuK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK1ljWKz8g2W"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed: int):\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqVH3YkZ8g2j"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "num_features = 10\n",
        "classes = [0, 1, 2, 3, 4]\n",
        "num_classes = len(classes)\n",
        "\n",
        "num_samples = 100\n",
        "num_train = 70\n",
        "num_test = num_samples - num_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_CUw9iQ8g2l"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "# We are creating a random feature set and a random label set.\n",
        "# The features and labels have no semantic meaning and might as well be garbage.\n",
        "\n",
        "set_seed(2022)\n",
        "\n",
        "features = np.random.random_sample((num_samples, num_features))\n",
        "labels = np.random.choice(classes, size = num_samples)\n",
        "\n",
        "# Train-test split\n",
        "x_train = features[:num_train]\n",
        "x_test = features[num_train:num_samples]\n",
        "\n",
        "x_train = torch.Tensor(x_train)\n",
        "x_test = torch.Tensor(x_test)\n",
        "\n",
        "y_train = labels[:num_train]\n",
        "y_test = labels[num_train:num_samples]\n",
        "\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISGKboaW8g2p"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "print(f\"Train features: {x_train.shape}\")\n",
        "print(f\"Test features: {x_test.shape}\")\n",
        "\n",
        "print(f\"Train labels: {y_train.shape}\")\n",
        "print(f\"Train labels: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create train and test TensorDatasets from the respective numpy arrays"
      ],
      "metadata": {
        "id": "rop2qUMGxRS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJLmN-w78g2w"
      },
      "outputs": [],
      "source": [
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "train_dataset = ___\n",
        "test_dataset = ___\n",
        "\n",
        "#### YOUR CODE ENDS HERE ####"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dataloaders using the datasets created in the previous cell.\n",
        "Use a batch size of 64"
      ],
      "metadata": {
        "id": "d1BFcfJvxWV2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A66JuuQp8g2z"
      },
      "outputs": [],
      "source": [
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "batch_size = ___\n",
        "\n",
        "train_loader = ___\n",
        "test_loader = ___\n",
        "\n",
        "#### YOUR CODE ENDS HERE ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFfzN-oaL762"
      },
      "source": [
        "Network Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulyKVaak8g27"
      },
      "outputs": [],
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "# Number of neurons in the hidden layer of our MLP\n",
        "num_hidden = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the network MLP. Follow the comments to fill in the code"
      ],
      "metadata": {
        "id": "mi4gWOpSxiLv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPQMmDKbhwy9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, num_features, num_classes, num_hidden):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "        # define a linear layer with output channels as 32\n",
        "        self.hidden = ___\n",
        "        # Define a ReLU activation\n",
        "        self.relu = ___\n",
        "        # define a linear layer with output features corresponding to the number of classes\n",
        "        self.classifier = ___\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use the layers defined above in a sequential way (folow the same as the layer definitions above) and\n",
        "        # write the forward pass, use a relu activation after the hidden layer\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "        out = ___\n",
        "        out = ___\n",
        "        out = ___\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GkrWn_dfVyo"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIdgIfkAGXi9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "        # send the data, target to the device\n",
        "        data = ___\n",
        "        target = ___\n",
        "\n",
        "        # flush out the gradients stored in optimizer\n",
        "        ____\n",
        "\n",
        "        # pass the batch data to the model and assign the output\n",
        "        output = ___\n",
        "\n",
        "        # calculate the loss (use CrossEntropyLoss in pytorch)\n",
        "        loss = ___\n",
        "\n",
        "        # do a backward pass\n",
        "        ___\n",
        "\n",
        "        # update the weights\n",
        "        ___\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "        # Store loss\n",
        "        epoch_loss += loss.item() * data.shape[0]\n",
        "\n",
        "    print(f\"Train Average Loss: {epoch_loss/len(train_loader.dataset):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Inference"
      ],
      "metadata": {
        "id": "dtUkVJRrx2Zi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWEpNBtdHVWr",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader, criterion, mode):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "            # send data, target to the device\n",
        "            data = ___\n",
        "            target = ___\n",
        "\n",
        "            # pass the batch data to the model and assign the output\n",
        "            output = ___\n",
        "            #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "            test_loss += criterion(output, target).item() * data.shape[0]  # sum up batch loss\n",
        "            pred = output.argmax(dim = 1, keepdim = True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"{mode} Average loss: {test_loss:.2f}\")\n",
        "    print(f\"{mode} Accuracy: {correct}/{len(test_loader.dataset)} ({test_acc:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRebLHiriRsu"
      },
      "outputs": [],
      "source": [
        "set_seed(2022)\n",
        "\n",
        "num_epochs = 300\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "# check availability of GPU and set the device accordingly\n",
        "device = ___\n",
        "\n",
        "# Initialize MLP model\n",
        "model = ___\n",
        "\n",
        "# Define Adam Optimizer with a learning rate of 0.001\n",
        "optimizer = ___\n",
        "\n",
        "# Define CrossEntropyLoss as the criterion\n",
        "criterion = ___\n",
        "\n",
        "#### YOUR CODE ENDS HERE ####\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    print(f\"\\nEpoch: {epoch}/{num_epochs}\")\n",
        "\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, device, test_loader, criterion, mode = \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8U-700l8g3L"
      },
      "outputs": [],
      "source": [
        "print(sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_WXV-bY8g3J"
      },
      "source": [
        "\n",
        "### Q4. What are total number of parameters in the model?\n",
        "\n",
        "a) 8197 \\\\\n",
        "b) 18521 \\\\\n",
        "c) 8356 \\\\\n",
        "d) 9105"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVQZOy5M8g3O"
      },
      "outputs": [],
      "source": [
        "test(model, device, train_loader, criterion, mode = \"Train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maYYAzU28g3N"
      },
      "source": [
        "### Q5. Report the final train accuracy (Choose the closest option).\n",
        "\n",
        "a) 58% \\\\\n",
        "b) 93% \\\\\n",
        "c) 100% \\\\\n",
        "d) 89%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXEEd8YP8g3S"
      },
      "outputs": [],
      "source": [
        "test(model, device, test_loader, criterion, mode = \"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV3DSN3v0NBN"
      },
      "source": [
        "### Q6. Report the final test accuracy (Choose the closest option).\n",
        "\n",
        "a) 30% \\\\\n",
        "b) 40% \\\\\n",
        "c) 10% \\\\\n",
        "d) 70%"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}